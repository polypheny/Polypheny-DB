
options {
    STATIC = false;
    IGNORE_CASE = true;
    UNICODE_INPUT = true;
}

PARSER_BEGIN(MqlParserImpl)

package org.polypheny.db.mql.parser.impl;

import org.polypheny.db.runtime.PolyphenyDbContextException;
import org.polypheny.db.languages.mql.MqlAggregate;
import org.polypheny.db.languages.mql.MqlCount;
import org.polypheny.db.languages.mql.MqlCreateCollection;
import org.polypheny.db.languages.mql.MqlCreateView;
import org.polypheny.db.languages.mql.MqlDelete;
import org.polypheny.db.languages.mql.MqlDrop;
import org.polypheny.db.languages.mql.MqlFind;
import org.polypheny.db.languages.mql.MqlRenameCollection;
import org.polypheny.db.languages.mql.MqlFindAndModify;
import org.polypheny.db.languages.mql.MqlFindOneAndDelete;
import org.polypheny.db.languages.mql.MqlFindOneAndReplace;
import org.polypheny.db.languages.mql.MqlFindOneAndUpdate;
import org.polypheny.db.languages.mql.MqlInsert;
import org.polypheny.db.languages.mql.MqlNode;
import org.polypheny.db.languages.mql.MqlRemove;
import org.polypheny.db.languages.mql.MqlReplace;
import org.polypheny.db.languages.mql.MqlSave;
import org.polypheny.db.languages.mql.MqlUpdate;
import org.polypheny.db.languages.mql.MqlShowDatabase;
import org.polypheny.db.languages.mql.MqlUseDatabase;
import org.polypheny.db.languages.mql.MqlDropDatabase;
import org.polypheny.db.languages.mql.MqlAddPlacement;
import org.polypheny.db.languages.mql.MqlDeletePlacement;
import org.polypheny.db.languages.mql.parser.MqlAbstractParserImpl;
import org.polypheny.db.languages.mql.parser.MqlParseException;
import org.polypheny.db.languages.ParserPos;
import org.polypheny.db.languages.mql.parser.MqlParserUtil;
import org.polypheny.db.util.BsonUtil;
import org.polypheny.db.util.SourceStringReader;
import org.polypheny.db.languages.ParserFactory;

import org.bson.BsonDocument;
import org.bson.BsonValue;
import org.bson.BsonArray;

import java.io.Reader;
import java.util.Arrays;
import java.util.List;
import java.util.ArrayList;

/**
 * MongoDB query language (MQL) parser, generated from Parser.jj by JavaCC.
 *
 * The public wrapper for this parser is {@code MqlParser}.
**/
public class MqlParserImpl extends MqlAbstractParserImpl {

private static Metadata metadata;


      /**
       * ParserFactory implementation for creating parser.
       */
      public static final ParserFactory FACTORY = new ParserFactory() {
          public MqlAbstractParserImpl getParser(Reader reader) {
              final MqlParserImpl parser = new MqlParserImpl(reader);
              if (reader instanceof SourceStringReader) {
                  final String mql = ((SourceStringReader) reader).getSourceString();
                  parser.setOriginalMql(mql);
              }
            return parser;
          }
      };

      public MqlParseException normalizeException(Throwable ex)
      {
          try {
              if (ex instanceof ParseException) {
                  ex = cleanupParseException((ParseException) ex);
              }
              return convertException(ex);
          } catch (ParseException e) {
              throw new AssertionError(e);
          }
      }

      public Metadata getMetadata()
      {
          synchronized (MqlParserImpl.class) {
              if (metadata == null) {
                  metadata = new MetadataImpl(new MqlParserImpl(new java.io.StringReader("")));
              }
              return metadata;
          }
      }

      public MqlNode parseMqlExpressionEof() throws Exception
      {
          return Input();
      }

      public MqlNode parseMqlStmtEof() throws Exception
      {
          return Input();
      }

}

PARSER_END(MqlParserImpl)

<DEFAULT> SKIP : { " "
                 | "\t"
                 | "\n"
                 | "\r"
                 | "\f"
}

TOKEN : /* IDENTIFIERS */ // for nested documentValues check out Document_Splits()
{
< USE_DB: "use db" >
|
< BOOL: "true" | "false" >
|
< COMMA: "," >
|
< USE: "use " >
|
< DB: "db" >
|
< DROP: "drop(" >
|
< DROP_DATABASE: "dropDatabase(" >
|
< SAVE: "save" >
|
< REMOVE: "remove" >
|
< UPDATE: "update" >
|
< UPDATE_ONE: "updateOne" >
|
< UPDATE_MANY: "updateMany" >
|
< INSERT: "insert" >
|
< INSERT_MANY: "insertMany" >
|
< INSERT_ONE: "insertOne" >
|
< STORE: "store" >
|
< SHOWDB: ("show dbs" | "show databases") >
|
< REPLACE_ONE: "replaceOne" >
|
< FIND: "find" >
|
< FIND_ONE: "findOne" >
|
< FIND_AND_MODIFY: "findAndModify" >
|
< FIND_ONE_AND_REPLACE: "findOneAndReplace" >
|
< FIND_ONE_AND_DELETE: "findOneAndDelete" >
|
< FIND_ONE_AND_UPDATE: "findOneAndUpdate" >
|
< PRIMARY: "primary" >
|
< DELETE_ONE: "deleteOne" >
|
< DELETE_MANY: "deleteMany" >
|
< ADD_PLACEMENT: "addPlacement(" >
|
< DELETE_PLACEMENT: "deletePlacement(">
|
< CREATE_VIEW: "createView(" >
|
< CREATE_COLLECTION : "createCollection(" >
|
< RENAME_COLLECTION : "renameCollection(" >
|
< GET_COLLECTION : "getCollection(" >
|
< AGGREGATE : "aggregate" >
|
< COUNT : "count" >
|
< COUNT_DOC : "countDocuments" >
|
< ESTIMATECOUNT : "estimatedDocumentCount" >
|
< DOCUMENT: "{" (<LETTER>|<DIGIT>|<SYMBOL>)* "}" >
|
< COMMANDS: "(" (~[])* ")">
|
< ARRAY: "[" (<LETTER>|<DIGIT>|<SYMBOL>)* "]" >
|
< #SYMBOL: [".", ",", ":", ";", "!", "$", "\"", "'", "(", ")", " ", "\n", "{", "}", "[", "]","&","\\","/", "=", "<" ,">", "�","^", "~", "´", "@" ] | <MATH> >
|
< #MATH: ["*", "/", "-", "+"] >
|
< IDENTIFIER: <LETTER> (<LETTER>|<DIGIT>)* >
|
< #LETTER: ["_","a"-"z","A"-"Z","ö", "Ö", "ä", "Ä", "ü", "Ü", "à", "À", "ç","Ç", "á", "Á", "è", "È","í","Í", "î", "Î","ó","Ó","ò", "ô", "Ô", "Ò" , "í", "Í", "ë", "Ë", "â", "Â", "ï", "Ï", "é", "É", "ñ", "Ñ", "ß"] >
|
< #DIGIT: ["0"-"9"] >
|
< EOB: ")" >
|
< DOT: "." >
}

////////////////////////////////////////
////* copied from Parser.jj start */////
////////////////////////////////////////


/**
 * Converts a ParseException (local to this particular instantiation
 * of the parser) into a SqlParseException (common to all parsers).
 */
JAVACODE MqlParseException convertException(Throwable ex)
{
    if (ex instanceof MqlParseException) {
        return (MqlParseException) ex;
    }
    ParserPos pos = null;
    int[][] expectedTokenSequences = null;
    String[] tokenImage = null;
    if (ex instanceof ParseException) {
        ParseException pex = (ParseException) ex;
        expectedTokenSequences = pex.expectedTokenSequences;
        tokenImage = pex.tokenImage;
        if (pex.currentToken != null) {
            final Token token = pex.currentToken.next;
            pos = new ParserPos(
                token.beginLine,
                token.beginColumn,
                token.endLine,
                token.endColumn);
        }
    } else if (ex instanceof TokenMgrError) {
        TokenMgrError tme = (TokenMgrError) ex;
        expectedTokenSequences = null;
        tokenImage = null;
        // Example:
        //    Lexical error at line 3, column 24.  Encountered "#" after "a".
        final java.util.regex.Pattern pattern = java.util.regex.Pattern.compile(
            "(?s)Lexical error at line ([0-9]+), column ([0-9]+).*");
        java.util.regex.Matcher matcher = pattern.matcher(ex.getMessage());
        if (matcher.matches()) {
            int line = Integer.parseInt(matcher.group(1));
            int column = Integer.parseInt(matcher.group(2));
            pos = new ParserPos(line, column, line, column);
        }
    } else if (ex instanceof PolyphenyDbContextException) {
        // PolyphenyDbContextException is the standard wrapper for exceptions
        // produced by the validator, but in the parser, the standard is
        // SqlParseException; so, strip it away. In case you were wondering,
        // the PolyphenyDbContextException appears because the parser
        // occasionally calls into validator-style code such as
        // SqlSpecialOperator.reduceExpr.
        PolyphenyDbContextException ece =
            (PolyphenyDbContextException) ex;
        pos = new ParserPos(
            ece.getPosLine(),
            ece.getPosColumn(),
            ece.getEndPosLine(),
            ece.getEndPosColumn());
        ex = ece.getCause();
    }

    return new MqlParseException(
        ex.getMessage(), pos, expectedTokenSequences, tokenImage, ex);
}

/**
 * Removes or transforms misleading information from a parse exception.
 *
 * @param e dirty excn
 *
 * @return clean excn
 */
JAVACODE ParseException cleanupParseException(ParseException ex)
{
    if (ex.expectedTokenSequences == null) {
        return ex;
    }
    int iIdentifier = Arrays.asList(ex.tokenImage).indexOf("<IDENTIFIER>");

    // Find all sequences in the error which contain identifier. For
    // example,
    //       {<IDENTIFIER>}
    //       {A}
    //       {B, C}
    //       {D, <IDENTIFIER>}
    //       {D, A}
    //       {D, B}
    //
    // would yield
    //       {}
    //       {D}
    boolean id = false;
    final List<int[]> prefixList = new ArrayList<int[]>();
    for (int i = 0; i < ex.expectedTokenSequences.length; ++i) {
        int[] seq = ex.expectedTokenSequences[i];
        int j = seq.length - 1;
        int i1 = seq[j];
        if (i1 == iIdentifier) {
            int[] prefix = new int[j];
            System.arraycopy(seq, 0, prefix, 0, j);
            prefixList.add(prefix);
        }
    }

    if (prefixList.isEmpty()) {
        return ex;
    }

    int[][] prefixes = (int[][])
        prefixList.toArray(new int[prefixList.size()][]);

    // Since <IDENTIFIER> was one of the possible productions,
    // we know that the parser will also have included all
    // of the non-reserved keywords (which are treated as
    // identifiers in non-keyword contexts).  So, now we need
    // to clean those out, since they're totally irrelevant.

    final List<int[]> list = new ArrayList<int[]>();
    Metadata metadata = getMetadata();
    for (int i = 0; i < ex.expectedTokenSequences.length; ++i) {
        int [] seq = ex.expectedTokenSequences[i];
        String tokenImage = ex.tokenImage[seq[seq.length - 1]];
        String token = MqlParserUtil.getTokenVal(tokenImage);
        if (token == null  || !metadata.isNonReservedKeyword(token)) {
            list.add(seq);
            continue;
        }
        boolean match = matchesPrefix(seq, prefixes);
        if (!match) {
            list.add(seq);
        }
    }

    ex.expectedTokenSequences =
        (int [][]) list.toArray(new int [list.size()][]);
    return ex;
}

JAVACODE protected ParserPos getPos()
{
    return new ParserPos(
        token.beginLine,
        token.beginColumn,
        token.endLine,
        token.endColumn);
}

JAVACODE boolean matchesPrefix(int[] seq, int[][] prefixes)
{
    nextPrefix:
    for (int[] prefix : prefixes) {
        if (seq.length == prefix.length + 1) {
            for (int k = 0; k < prefix.length; k++) {
                if (prefix[k] != seq[k]) {
                    continue nextPrefix;
                }
            }
            return true;
        }
    }
    return false;
}

//////////////////////////////////////
////* copied from Parser.jj end */////
//////////////////////////////////////



/** Root production. */
MqlNode Input() :
{
 MqlNode n;
}
{
    /** only one statement for now **/
    n = Statement() <EOF>
    {return n;}
}

/** Brace matching production. */
MqlNode Statement() :
{
    MqlNode n;
    String name;
}
{
    <DB> <DOT> n=Db_Statement()
    {return n;}
    |
    <USE> name = Literal()
    {return new MqlUseDatabase( getPos(), name);}
    |
    <USE_DB>
    {return new MqlShowDatabase( getPos() );}
}


MqlNode Db_Statement():
{
    MqlNode n;
    String name;
    String source;
    BsonArray array = null;
    BsonDocument doc = null;
}
{
    (
        <CREATE_COLLECTION> name = Literal() [<COMMA> doc = Document()  ]")"
        {n = new MqlCreateCollection(getPos(), name, doc);}
        (Details(n))* (Primary(n))*

    |
        <GET_COLLECTION> name = Literal() ")"
        < DOT > n = Collection_Statement(name)
        (Details(n))* (Primary(n))*

    |
        <CREATE_VIEW> name = Literal() < COMMA > source = Literal() (< COMMA > array=Array() )? ")"
        {n = new MqlCreateView(getPos(), name, source, array);}
    |
        <DROP_DATABASE> ")"
        {n = new MqlDropDatabase(getPos());}
    |
        n = Collection_Statement(null)
    |
        name=Literal() < DOT > n=Collection_Statement(name)
    )
    {return n;}
}

MqlNode Collection_Statement(String collection):
{
    MqlNode n;
}
{
    (
        n = Find_Statement(collection)
    |
        n = Find_And_Statement(collection)
    |
        n = Insert_Statement(collection)
    |
        n = Count_Statement(collection)
    |
        n = Estimate_Count_Statement(collection)
    |
        n = Aggregate_Statement(collection)
    |
        n = Update_Statement(collection)
    |
        n = Replace_Statement(collection)
    |
        n = Rename_Statement(collection)
    |
        n = Drop_Statement(collection)
    |
        n = Modify_Placement(collection)
    |
        n = Delete_Statement(collection)
    |
        n = Save_Statement(collection)
    |
        n = Remove_Statement(collection)
    )
    {return n;}

}

MqlNode Modify_Placement(String collection):
{
    List<String> stores = new ArrayList();
    String store = null;
}
{
    <ADD_PLACEMENT> store=Literal() <EOB>
    {
        stores.add( store  );
        return new MqlAddPlacement( getPos(), collection, stores );
    }
    |
    <DELETE_PLACEMENT> store=Literal() <EOB>
    {
        stores.add( store );
        return new MqlDeletePlacement( getPos(), collection, stores );
    }
}


MqlNode Delete_Statement(String collection):
{
    List<BsonDocument> docs = new ArrayList();
    boolean onlyOne = false;
}
{
    (
        <DELETE_ONE>
        {onlyOne = true;}
        |
        <DELETE_MANY>
    )
    [docs=Document_Splits()]
    {
        if ( docs.size() == 2 ){
            return new MqlDelete(getPos(), collection, docs.get(0), docs.get(1), onlyOne);
        }else if ( docs.size() == 1 ){
            return new MqlDelete(getPos(), collection, docs.get(0), null, onlyOne);
        }else {
            throw new RuntimeException( "The used operation needs a least one empty document." );
        }

    }
}

MqlNode Rename_Statement(String collection):
{
    String newName;
    boolean dropTarget = false;
}
{
    < RENAME_COLLECTION > newName = Literal() [<COMMA> dropTarget=Bool() ] ")"
    {
        return new MqlRenameCollection(getPos(), collection, newName, dropTarget);
    }
}

MqlNode Drop_Statement(String collection):
{
    BsonDocument doc = null;
}
{
    <DROP>[doc=Document()]")"
    {return new MqlDrop(getPos(), collection);}
}

MqlNode Remove_Statement(String collection):
{
    BsonDocument doc;
}
{
    <REMOVE> "("doc=Document()")"
    {return new MqlRemove(getPos(), collection, doc);}
}


MqlNode Save_Statement(String collection):
{
    BsonDocument doc;
}
{
    <SAVE> doc=Document()
    {return new MqlSave(getPos(), collection, doc);}
}


MqlNode Replace_Statement(String collection):
{
    BsonDocument doc;
}
{
    <REPLACE_ONE> doc=Document()
    {return new MqlReplace(getPos(), collection, doc);}
}

MqlNode Update_Statement(String collection):
{
    List<BsonValue> docs;
    boolean onlyOne = false;
}
{
    (
        <UPDATE>
        |
        <UPDATE_MANY>
        |
        <UPDATE_ONE>
        {onlyOne = true;}
    )
    docs=Bson_Splits()
    {
        if ( docs.size() < 2 || !docs.get(0).isDocument() ){
            throw new RuntimeException( "Update needs a query and update document." );
        }

        if ( docs.size() == 3 ){
            if (!docs.get(2).isDocument()) {
                throw new RuntimeException( "Options for update need to be a document." );
            }

            return new MqlUpdate(getPos(), collection, docs.get(0).asDocument(), docs.get(1), docs.get(2).asDocument(), onlyOne );
        }else if ( docs.size() == 2 ) {
            return new MqlUpdate(getPos(), collection, docs.get(0).asDocument(), docs.get(1), null, onlyOne );
        }else {
            throw new RuntimeException( "An update needs at least a filter and a update document." );
        }
    }
}

MqlNode Aggregate_Statement(String collection):
{
    List<BsonValue> docs;
}
{
    <AGGREGATE> docs=Bson_Splits()
    {
        if ( docs.size() == 1 && docs.get(0).isArray() ) {
            return new MqlAggregate(getPos(), collection, docs.get(0).asArray(), null );
        }else if ( docs.size() == 2 && docs.get(0).isArray() && docs.get(1).isDocument() ){
            return new MqlAggregate(getPos(), collection, docs.get(0).asArray(), docs.get(1).asDocument() );
        }else {
            throw new RuntimeException("The aggregation pipepline needs either either an array or an array and a options document");
        }
    }
}

MqlNode Count_Statement(String collection):
{
    List<BsonDocument> docs = new ArrayList();
    boolean isEstimate = false;
}
{
    (
        <COUNT>
        |
        <COUNT_DOC>
    )
    docs=Document_Splits()
    {
        if ( docs.size() == 2 ){
            return new MqlCount(getPos(), collection, docs.get(0), docs.get(1), isEstimate);
        }else if ( docs.size() == 1 ){
            return new MqlCount(getPos(), collection, docs.get(0), null, isEstimate);
        }else {
            throw new RuntimeException( "The used operation needs a least one empty document." );
        }

    }

}

MqlNode Estimate_Count_Statement(String collection):
{
    BsonDocument doc = null;
}
{
    <ESTIMATECOUNT> [doc=Document()]
    {
        return new MqlCount(getPos(), collection, null, doc, true);
    }

}


MqlNode Find_Statement(String collection):
{
    List<BsonDocument> docs = new ArrayList();
    BsonDocument query = null;
    BsonDocument projection = null;
    boolean onlyOne = false;
}
{
    (
        <FIND>
        |
        <FIND_ONE>
        {onlyOne = true;}
    )
    docs=Document_Splits()
    {
        if ( docs.size() == 2 ){
            return new MqlFind( getPos(), collection, docs.get(0), docs.get(1), onlyOne );
        }else if ( docs.size() == 1 ){
            return new MqlFind( getPos(), collection, docs.get(0), null, onlyOne );
        }else {
            return new MqlFind( getPos(), collection, null, null, onlyOne );
        }

    }
}

MqlNode Find_And_Statement(String collection):
{
    BsonDocument doc;
    List<BsonDocument> docs = new ArrayList();
    List<BsonValue> mixed = new ArrayList();
}
{
    < FIND_AND_MODIFY > "(" doc=Document() ")"
    {return new MqlFindAndModify( getPos(), collection, doc);}
    |
    < FIND_ONE_AND_DELETE > docs=Document_Splits()
    {
        if( docs.size() == 2 ){
            return new MqlFindOneAndDelete( getPos(), collection, docs.get(0), docs.get(1));
        }else if (docs.size() == 1 ){
            return new MqlFindOneAndDelete( getPos(), collection, docs.get(0), null );
        }else {
            throw new RuntimeException("findOneAndDelete requires a filter document");
        }
    }
    |
    <FIND_ONE_AND_REPLACE> docs=Document_Splits()
    {
        if ( docs.size() == 3 ) {
            return new MqlFindOneAndReplace( getPos(), collection, docs.get(0), docs.get(1), docs.get(2));
        } else if( docs.size() == 2 ){
            return new MqlFindOneAndReplace( getPos(), collection, docs.get(0), docs.get(1), null);
        } else {
            throw new RuntimeException("findOneAndReplace requires a filter and a replacement document");
        }
    }
    |
    <FIND_ONE_AND_UPDATE> mixed=Bson_Splits()
    {
        if ( mixed.size() == 3 ) {
            return new MqlFindOneAndUpdate( getPos(), collection, docs.get(0).asDocument(), docs.get(1), docs.get(2).asDocument());
        } else if( docs.size() == 2 ){
            return new MqlFindOneAndUpdate( getPos(), collection, docs.get(0).asDocument(), docs.get(1), null);
        } else {
            throw new RuntimeException("findOneAndDelete requires a filter document, and an update document");
        }
    }
}

MqlNode Insert_Statement(String collection):
{
    List<BsonValue> docs = new ArrayList();
}
{
    (
        <INSERT>
        |
        <INSERT_MANY>
        |
        <INSERT_ONE>
    )
    docs=Bson_Splits()
    {
        if ( docs.size() == 2 ){
            if ( docs.get(1).isDocument() ) {
                throw new RuntimeException( "Options need to be a document" );
            }
            return new MqlInsert( getPos(), collection, docs.get(0), docs.get(1).asDocument() );
        }else if ( docs.size() == 1 ) {
            return new MqlInsert( getPos(), collection, docs.get(0), null );
        }else {
            throw new RuntimeException( "Insert requires a least one document" );
        }

    }

}

BsonDocument Document():
{
    Token t;
    String text;
}
{
    (
        t=<DOCUMENT>
        {text = t.image;}
        |
        t=<COMMANDS>
        {text = t.image.substring(1, t.image.length() - 1 );}
    )
    {
        return BsonDocument.parse( BsonUtil.fixBson( text ));
    }
}

List<BsonDocument> Document_Splits():
{
    List<BsonValue> values;
}
{
    values = Bson_Splits()
    { return BsonUtil.asDocumentCollection(values);}
}

boolean Bool():
{
    Token t;
}
{
    t=< BOOL >
    {
        return Boolean.parseBoolean(t.image);
    }
}

// due to the LL approach of JavaCC we have to parse Documents besides oneanother ourself
// as identifier { document } handles {{}} and {},{} the same ( longest pattern is matched )
List<BsonValue> Bson_Splits():
{
    Token t;
}
{
    t=< COMMANDS >
    {
        if( t.image.trim().equals("") ){
            return new BsonArray();
        }else {
            return BsonArray.parse( BsonUtil.fixBson( "[" + t.image.substring(1, t.image.length() - 1 ) + "]" ) );
        }
    }
}

BsonArray Array():
{
    Token t;
}
{
    t=<ARRAY>
    {
        return BsonArray.parse( BsonUtil.fixBson(t.image) );
    }
}

void Literal_List(List<String> cols):
{
    String name;
}
{
    name=Literal()
    {cols.add(name);}
    [< COMMA > Literal_List(cols)]
}

String Literal():
{
    Token t;
}
{
    (
    "\"" t=<IDENTIFIER> "\""
    |
    t=<IDENTIFIER>
    )
    {return t.image;}
}


void Details( MqlNode node ):
{
    List<String> stores = new ArrayList();
}
{
    ".store(" Literal_List(stores) < EOB >
    {node.setStores(stores);}
}

void Primary( MqlNode node ):
{
    List<String> cols = new ArrayList();
}
{
    ".primary(" Literal_List(cols) < EOB >
    {node.setPrimary( cols );}
}